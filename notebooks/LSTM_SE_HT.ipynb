{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#!/usr/bin/env python3\n","# LSTM(SE) - Hypertuned, audit-ready, pure-sign trading, finalisation pack\n","\n","import os, sys, json, math, time, random, hashlib, platform, warnings, zipfile\n","from pathlib import Path\n","from datetime import datetime\n","from typing import List, Tuple, Dict, Any, Optional\n","\n","# ---- CUDA determinism env must be set BEFORE any torch CUDA checks ----\n","os.environ.setdefault(\"CUBLAS_WORKSPACE_CONFIG\", \":4096:8\")  # ensures deterministic GEMMs (where supported)\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","import matplotlib.pyplot as plt\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","# -------------------- determinism --------------------\n","RANDOM_SEED = 1337\n","random.seed(RANDOM_SEED)\n","np.random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(RANDOM_SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","try:\n","    torch.use_deterministic_algorithms(True)\n","except Exception:\n","    pass\n","torch.set_num_threads(1)  # optional stricter reproducibility\n","\n","# -------------------- config --------------------\n","CONFIG = {\n","    \"MODEL_ID\": \"LSTM_SE_TUNED\",\n","    \"REPORTED_NAME\": \"LSTM (sentiment-enhanced) - monthly refit\",\n","    \"TICKERS\": [\"AAPL\",\"AMZN\",\"MSFT\",\"TSLA\",\"AMD\"],\n","    \"INPUT_DIR\": \"final_inputs\",\n","    \"OUT_ROOT\": \"LSTM_SE_TUNED_FINAL\",\n","\n","    # Fixed splits\n","    \"TRAIN_START\": \"2021-02-03\",\n","    \"TRAIN_END\":   \"2022-12-30\",\n","    \"VAL_START\":   \"2023-01-03\",\n","    \"VAL_END\":     \"2023-05-31\",\n","    \"TEST_START\":  \"2023-06-01\",\n","    \"TEST_END\":    \"2023-12-28\",\n","    \"ASSERT_N_TEST\": 146,\n","\n","    # Modelling\n","    \"SEQ_LEN\": 90,\n","    \"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n","    \"EPS_DA\": 0.0010,      # for Directional Accuracy only (not used for trading)\n","    \"EPOCHS\": 500,\n","\n","    # Lean, defensible Val-only search space (per ticker)\n","    \"SEARCH_SPACE\": {\n","        \"hidden_size\": [32, 48, 64, 96],\n","        \"num_layers\": [1, 2],\n","        \"dropout\": [0.0, 0.1, 0.2],\n","        \"optim\": [\"Adam\", \"AdamW\"],\n","        \"lr\": [1e-4, 3e-4, 1e-3],\n","        \"batch_size\": [32, 64],\n","        \"patience\": [10, 15],\n","        \"weight_decay\": [0.0, 1e-4],\n","        \"grad_clip_norm\": [None, 1.0]\n","    },\n","    \"N_TRIALS\": 24,\n","\n","    # Global invariants (clock/target provenance)\n","    \"CLOCK_INVARIANTS\": {\n","        \"market_timezone\": \"America/New_York\",\n","        \"cutoff_local_time\": \"16:00:00\",\n","        \"no_forward_fill_past_cutoff\": True,\n","        \"sentiment_zero_encoding_on_no_activity_days\": True\n","    },\n","\n","    # Code provenance (adapted example)\n","    \"PROVENANCE\": {\n","        \"repo_name\": \"keras-team/keras-io\",\n","        \"repo_url\": \"https://github.com/keras-team/keras-io\",\n","        \"licence\": \"Apache-2.0\",\n","        \"commit_sha\": \"f7e54711205ca29a06577a04047b4a40df32fdec\",\n","        \"imported_files\": \"examples/timeseries/timeseries_weather_forecasting.py\",\n","        \"adaptation_notes\": \"Adapted stacked-LSTM; project loaders; zero-preserving scaler; monthly refit; EMR metrics.\"\n","    },\n","\n","    # Optional peer features manifest for parity when packs are not present\n","    \"PEER_FEATURES_FILE\": \"peer_features_manifest.json\"\n","}\n","\n","# -------------------- IO --------------------\n","def read_csv(ticker: str) -> pd.DataFrame:\n","    p = Path(CONFIG[\"INPUT_DIR\"]) / f\"{ticker}_input.csv\"\n","    if not p.exists():\n","        raise FileNotFoundError(f\"Missing input file: {p}\")\n","    df = pd.read_csv(p)\n","    if \"date\" not in df.columns or \"Target\" not in df.columns:\n","        raise RuntimeError(f\"{p} must include 'date' and 'Target'\")\n","    df[\"date\"] = pd.to_datetime(df[\"date\"])\n","    if df[\"date\"].duplicated().any():\n","        dups = df[df[\"date\"].duplicated()][\"date\"].unique()[:5]\n","        raise RuntimeError(f\"{p} has duplicate dates (e.g. {dups})\")\n","    df = df.sort_values(\"date\").reset_index(drop=True)\n","    if df[\"Target\"].isna().any():\n","        raise RuntimeError(f\"{p} has NaNs in Target\")\n","    if \"Close\" in df and df[\"Close\"].isna().any():\n","        raise RuntimeError(f\"{p} has NaNs in Close\")\n","    return df\n","\n","def slice_dates(df: pd.DataFrame, a: str, b: str) -> pd.DataFrame:\n","    m = (df[\"date\"] >= pd.to_datetime(a)) & (df[\"date\"] <= pd.to_datetime(b))\n","    return df.loc[m].reset_index(drop=True)\n","\n","def group_cols(cols: List[str]) -> Tuple[List[str], List[str]]:\n","    sents = [c for c in cols if c.startswith((\"Tw_\", \"Rd_\", \"Nw_SP500_\"))]\n","    base  = [c for c in cols if c not in sents and c not in [\"date\", \"ticker\", \"Target\"]]\n","    return base, sents\n","\n","# -------------------- scalers --------------------\n","class ZeroPreservingStandardiser:\n","    def __init__(self, sent_cols: List[str]):\n","        self.sent_cols = set(sent_cols)\n","        self.mu, self.sd = {}, {}\n","        self.fitted = False\n","    def fit(self, X: pd.DataFrame):\n","        for c in X.columns:\n","            if c in self.sent_cols:\n","                v = X[c].to_numpy()\n","                nz = v[v != 0]\n","                mu = float(np.mean(nz)) if len(nz) else 0.0\n","                sd = float(np.std(nz)) if len(nz) else 1.0\n","                self.mu[c] = mu\n","                self.sd[c] = sd if sd > 1e-12 else 1.0\n","            else:\n","                mu = float(np.mean(X[c])); sd = float(np.std(X[c]))\n","                self.mu[c] = mu; self.sd[c] = sd if sd > 1e-12 else 1.0\n","        self.fitted = True\n","        return self\n","    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n","        if not self.fitted:\n","            raise RuntimeError(\"Scaler not fitted\")\n","        Z = X.copy()\n","        for c in X.columns:\n","            if c in self.sent_cols:\n","                v = Z[c].to_numpy(dtype=float)\n","                mask = (v != 0)\n","                v2 = v.copy()\n","                v2[mask] = (v2[mask] - self.mu[c]) / self.sd[c]\n","                v2[~mask] = 0.0\n","                Z[c] = v2\n","            else:\n","                Z[c] = (Z[c] - self.mu[c]) / self.sd[c]\n","        return Z\n","\n","def zero_preservation_report(raw_df: pd.DataFrame, scaled_df: pd.DataFrame, sent_cols: List[str], out_csv: Path, atol: float = 1e-12):\n","    rows, violations = [], 0\n","    if not sent_cols:\n","        pd.DataFrame([{\"column\":\"<none>\",\"raw_zero_count\":0,\"preserved_zero_count\":0,\"violations\":0,\"ok\":True,\"zeros_after_total\":0}]).to_csv(out_csv, index=False)\n","        return\n","    for c in sent_cols:\n","        raw = raw_df[c].to_numpy()\n","        if not np.all(np.isfinite(raw)):\n","            raise RuntimeError(f\"Non-finite values detected in sentiment column '{c}'\")\n","        sca = scaled_df[c].to_numpy()\n","        mask_raw_zero = np.isfinite(raw) & (raw == 0)\n","        n_raw_zeros = int(mask_raw_zero.sum())\n","        n_preserved = int(np.isclose(sca[mask_raw_zero], 0.0, atol=atol, rtol=0).sum())\n","        v = max(n_raw_zeros - n_preserved, 0)\n","        violations += v\n","        rows.append({\n","            \"column\": c,\n","            \"raw_zero_count\": n_raw_zeros,\n","            \"preserved_zero_count\": n_preserved,\n","            \"violations\": v,\n","            \"ok\": (v == 0),\n","            \"zeros_after_total\": int(np.isclose(sca, 0.0, atol=atol, rtol=0).sum())\n","        })\n","    pd.DataFrame(rows).to_csv(out_csv, index=False)\n","    if violations > 0:\n","        raise RuntimeError(f\"Zero-preservation check failed: {violations} violations\")\n","\n","# -------------------- datasets / helpers --------------------\n","class SeqDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = X.astype(np.float32); self.y = y.astype(np.float32)\n","    def __len__(self): return self.X.shape[0]\n","    def __getitem__(self, i): return self.X[i], self.y[i]\n","\n","def windowise(df: pd.DataFrame, feat_cols: List[str], L: int):\n","    n = len(df)\n","    if n <= L:\n","        raise ValueError(f\"Not enough rows ({n}) to form windows with seq_len={L}\")\n","    X = df[feat_cols].to_numpy(); y = df[\"Target\"].to_numpy()\n","    xs, ys = [], []\n","    for i in range(n - L):\n","        xs.append(X[i:i+L, :]); ys.append(y[i+L])\n","    return np.stack(xs).astype(np.float32), np.array(ys, dtype=np.float32)\n","\n","def naive_last_close_from_windowised(close_series: pd.Series, L: int) -> np.ndarray:\n","    \"\"\"\n","    Given the same df used for windowise (length N), the targets are y[L:].\n","    For each target at t>=L, return Close_{t-1}. Length is N-L.\n","    \"\"\"\n","    c = close_series.to_numpy()\n","    return c[L-1:-1]  # indices [L-1 .. N-2] -> length N-L\n","\n","def feature_stable_set(train_by_t: Dict[str, pd.DataFrame], val_by_t: Dict[str, pd.DataFrame]) -> List[str]:\n","    first_t = next(iter(train_by_t.keys()))\n","    base0, sents0 = group_cols(list(train_by_t[first_t].columns))\n","    feats0 = [c for c in base0 + sents0 if c not in [\"date\", \"ticker\", \"Target\"]]\n","    tr0, va0 = train_by_t[first_t], val_by_t[first_t]\n","    keep = {c for c in feats0 if float(tr0[c].std()) > 0 and float(va0[c].std()) > 0}\n","    for t in train_by_t:\n","        tr, va = train_by_t[t], val_by_t[t]\n","        base, sents = group_cols(list(tr.columns))\n","        feats = [c for c in base + sents if c not in [\"date\", \"ticker\", \"Target\"]]\n","        ok = {c for c in feats if float(tr[c].std()) > 0 and float(va[c].std()) > 0}\n","        keep = keep & ok\n","    out = sorted(list(keep))\n","    if \"Close\" in feats0 and \"Close\" not in out:\n","        out = sorted(list(set(out + [\"Close\"])))\n","    return out\n","\n","def monthly_boundaries(te_block: pd.DataFrame) -> List[int]:\n","    d = te_block.copy()\n","    ym = d[\"date\"].dt.to_period(\"M\")\n","    starts = (ym != ym.shift()).to_numpy()\n","    return np.flatnonzero(starts).tolist()  # positional offsets\n","\n","# -------------------- model --------------------\n","class LSTMReg(nn.Module):\n","    def __init__(self, n_in, hidden, layers, dropout):\n","        super().__init__()\n","        self.lstm = nn.LSTM(input_size=n_in, hidden_size=hidden, num_layers=layers,\n","                            batch_first=True, dropout=(dropout if layers > 1 else 0.0))\n","        self.head = nn.Linear(hidden, 1)\n","    def forward(self, x):\n","        out, _ = self.lstm(x)\n","        h = out[:, -1, :]\n","        y = self.head(h).squeeze(-1)\n","        return y\n","\n","def build_loader(X, y, bs):\n","    return DataLoader(SeqDataset(X, y), batch_size=bs, shuffle=False,\n","                      num_workers=0, pin_memory=torch.cuda.is_available(), drop_last=False)\n","\n","def train_one(model, train_loader, val_loader, cfg):\n","    dev = CONFIG[\"DEVICE\"]\n","    model = model.to(dev)\n","    if cfg[\"optim\"] == \"Adam\":\n","        opt = torch.optim.Adam(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n","    else:\n","        opt = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n","    loss_fn = nn.MSELoss()\n","    best = {\"val\": float(\"inf\"), \"state\": None, \"ep\": -1, \"curve\": []}\n","    bad = 0\n","    for ep in range(CONFIG[\"EPOCHS\"]):\n","        model.train()\n","        tr_sum, tr_n = 0.0, 0\n","        for xb, yb in train_loader:\n","            xb, yb = xb.to(dev).float(), yb.to(dev).float()\n","            opt.zero_grad()\n","            l = loss_fn(model(xb), yb)\n","            l.backward()\n","            if cfg[\"grad_clip_norm\"]:\n","                nn.utils.clip_grad_norm_(model.parameters(), cfg[\"grad_clip_norm\"])\n","            opt.step()\n","            tr_sum += l.item() * len(xb); tr_n += len(xb)\n","        model.eval()\n","        vs, vn = 0.0, 0\n","        with torch.no_grad():\n","            for xb, yb in val_loader:\n","                xb, yb = xb.to(dev).float(), yb.to(dev).float()\n","                vs += loss_fn(model(xb), yb).item() * len(xb); vn += len(xb)\n","        v = vs / max(1, vn)\n","        best[\"curve\"].append((ep, tr_sum / max(1, tr_n), v))\n","        if v < best[\"val\"] - 1e-9:\n","            best[\"val\"] = v\n","            best[\"state\"] = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n","            best[\"ep\"] = ep\n","            bad = 0\n","        else:\n","            bad += 1\n","            if bad >= cfg[\"patience\"]:\n","                break\n","    epochs_run = ep + 1\n","    stopped_early = (bad >= cfg[\"patience\"]) and (epochs_run < CONFIG[\"EPOCHS\"])\n","    if best[\"state\"] is not None:\n","        model.load_state_dict(best[\"state\"])\n","    return model, best, {\"epochs_run\": int(epochs_run), \"early_stop_triggered\": bool(stopped_early), \"best_epoch\": int(best[\"ep\"]), \"best_val_loss\": float(best[\"val\"])}\n","\n","def predict_tensor(model, X):\n","    dev = CONFIG[\"DEVICE\"]\n","    model = model.to(dev); model.eval()\n","    out = []\n","    with torch.inference_mode():\n","        for i in range(0, len(X), 1024):\n","            xb = torch.from_numpy(X[i:i+1024]).to(dev).float()\n","            out.append(model(xb).cpu().numpy())\n","    return np.concatenate(out, axis=0)\n","\n","# -------------------- metrics --------------------\n","def rmse(a, b): return float(np.sqrt(np.mean((a - b) ** 2)))\n","def mae(a, b):  return float(np.mean(np.abs(a - b)))\n","\n","def theils_u2(y_true, y_hat, y_naive):\n","    den = rmse(y_true, y_naive)\n","    return float(rmse(y_true, y_hat) / (den if den > 1e-12 else 1.0))\n","\n","def directional_accuracy_eps(y_true, y_hat, y_naive, eps):\n","    true_ret = (y_true - y_naive) / np.clip(y_naive, 1e-12, None)\n","    pred_ret = (y_hat - y_naive) / np.clip(y_naive, 1e-12, None)\n","    s_true = np.where(np.abs(true_ret) <= eps, 0, np.sign(true_ret))\n","    s_pred = np.where(np.abs(pred_ret) <= eps, 0, np.sign(pred_ret))\n","    mask = (s_true != 0)\n","    if not np.any(mask):\n","        return float(\"nan\"), 0.0, 0\n","    return float(np.mean(s_true[mask] == s_pred[mask])), float(np.mean(mask)), int(np.sum(mask))\n","\n","def pure_sign_trading_metrics(y_true, y_hat, y_naive, bps, verbose: bool = False):\n","    assert len(y_true) == len(y_hat) == len(y_naive), \"Length mismatch in trading metrics.\"\n","    true_ret = (y_true - y_naive) / np.clip(y_naive, 1e-12, None)\n","    pred_ret = (y_hat - y_naive) / np.clip(y_naive, 1e-12, None)\n","    pos = np.sign(pred_ret).astype(float)  # {-1,0,+1}; exact ties -> 0\n","\n","    # Turnover and per-change costs (clean assignment)\n","    if len(pos) > 1:\n","        delta = (np.abs(np.diff(pos)) > 0)\n","        turnover = int(np.sum(delta))\n","    else:\n","        delta = np.array([], dtype=bool)\n","        turnover = 0\n","    costs = np.zeros_like(pos, dtype=float)\n","    if len(pos) > 1:\n","        costs[1:] = delta.astype(float) * (bps / 10000.0)\n","\n","    strategy_ret = pos * true_ret - costs\n","    mu = float(np.mean(strategy_ret))\n","    sd = float(np.std(strategy_ret, ddof=0))\n","    sharpe = float(np.sqrt(252.0) * mu / sd) if sd > 0 else 0.0\n","    curve = np.cumprod(1.0 + strategy_ret)\n","    if curve.size:\n","        peak = np.maximum.accumulate(curve); maxdd = float(np.max(1.0 - curve / peak))\n","    else:\n","        maxdd = 0.0\n","    if verbose:\n","        total_cost = (bps / 10000.0) * float(np.sum(delta))\n","        print(f\"[Trading sanity] bps={bps:.1f} mean(ret)={np.mean(true_ret):.6g} std(ret)={np.std(true_ret):.6g} \"\n","              f\"n_changes={turnover} total_cost={total_cost:.6g}\")\n","    return sharpe, maxdd, turnover\n","\n","# -------------------- misc utils --------------------\n","def features_sha256(feats: List[str]) -> str:\n","    blob = \"\\n\".join([str(x) for x in feats]).encode(\"utf-8\")\n","    return hashlib.sha256(blob).hexdigest()\n","\n","def save_training_curves_png(path: Path, curves: List[Tuple[int, float, float]], title: str = \"\", annotate: Optional[Dict[str, Any]] = None):\n","    fig = plt.figure(figsize=(6, 4))\n","    ep = [e for e, _, _ in curves]\n","    tr = [t for _, t, _ in curves]\n","    va = [v for _, _, v in curves]\n","    plt.plot(ep, tr, label=\"train\"); plt.plot(ep, va, label=\"val\")\n","    plt.xlabel(\"epoch\"); plt.ylabel(\"MSE (original units)\")\n","    if title: plt.title(title)\n","    plt.legend(); plt.tight_layout()\n","    if annotate:\n","        txt = f\"best_ep={annotate.get('best_epoch')}, best_val={annotate.get('best_val_loss'):.4g}\\n\" \\\n","              f\"epochs_run={annotate.get('epochs_run')}, ES={annotate.get('early_stop_triggered')}\"\n","        plt.gcf().text(0.99, 0.02, txt, ha=\"right\", va=\"bottom\", fontsize=8)\n","    fig.savefig(path, dpi=160); plt.close(fig)\n","\n","def compute_param_count(n_in: int, cfg: Dict[str, Any]) -> int:\n","    m = LSTMReg(n_in=n_in, hidden=cfg[\"hidden_size\"], layers=cfg[\"num_layers\"], dropout=cfg[\"dropout\"])\n","    return int(sum(p.numel() for p in m.parameters()))\n","\n","# -------------------- tuning (per ticker, Val-only) --------------------\n","def run_search_for_ticker(ticker: str,\n","                          df_by_ticker: Dict[str, pd.DataFrame],\n","                          feat_cols: List[str],\n","                          sent_cols: List[str],\n","                          out_root: Path) -> Dict[str, Any]:\n","    full = df_by_ticker[ticker]\n","    tr = slice_dates(full, CONFIG[\"TRAIN_START\"], CONFIG[\"TRAIN_END\"])\n","    va = slice_dates(full, CONFIG[\"VAL_START\"], CONFIG[\"VAL_END\"])\n","\n","    sc = ZeroPreservingStandardiser(sent_cols).fit(tr[feat_cols])\n","    tr_s = tr.copy(); va_s = va.copy()\n","    tr_s[feat_cols] = sc.transform(tr[feat_cols]); va_s[feat_cols] = sc.transform(va[feat_cols])\n","\n","    Xtr, Ytr = windowise(tr_s, feat_cols, CONFIG[\"SEQ_LEN\"])\n","    va_full = pd.concat([tr_s.tail(CONFIG[\"SEQ_LEN\"]), va_s], ignore_index=True)\n","    Xva, Yva = windowise(va_full, feat_cols, CONFIG[\"SEQ_LEN\"])\n","\n","    # --- ESSENTIAL FIX: naïve last-close in ORIGINAL units (raw Close) ---\n","    va_full_close_raw = pd.concat([tr.tail(CONFIG[\"SEQ_LEN\"])[\"Close\"], va[\"Close\"]], ignore_index=True)\n","    last_naive_va = naive_last_close_from_windowised(va_full_close_raw, CONFIG[\"SEQ_LEN\"])\n","    # ---------------------------------------------------------------------\n","\n","    rows, best, best_id = [], None, None\n","    search_seed = RANDOM_SEED\n","\n","    for i in range(CONFIG[\"N_TRIALS\"]):\n","        cfg = {\n","            \"hidden_size\": random.choice(CONFIG[\"SEARCH_SPACE\"][\"hidden_size\"]),\n","            \"num_layers\": random.choice(CONFIG[\"SEARCH_SPACE\"][\"num_layers\"]),\n","            \"dropout\": random.choice(CONFIG[\"SEARCH_SPACE\"][\"dropout\"]),\n","            \"optim\": random.choice(CONFIG[\"SEARCH_SPACE\"][\"optim\"]),\n","            \"lr\": random.choice(CONFIG[\"SEARCH_SPACE\"][\"lr\"]),\n","            \"batch_size\": random.choice(CONFIG[\"SEARCH_SPACE\"][\"batch_size\"]),\n","            \"patience\": random.choice(CONFIG[\"SEARCH_SPACE\"][\"patience\"]),\n","            \"weight_decay\": random.choice(CONFIG[\"SEARCH_SPACE\"][\"weight_decay\"]),\n","            \"grad_clip_norm\": random.choice(CONFIG[\"SEARCH_SPACE\"][\"grad_clip_norm\"]),\n","            \"seq_len\": CONFIG[\"SEQ_LEN\"]\n","        }\n","        tr_dl = build_loader(Xtr, Ytr, cfg[\"batch_size\"])\n","        va_dl = build_loader(Xva, Yva, cfg[\"batch_size\"])\n","        model = LSTMReg(n_in=len(feat_cols), hidden=cfg[\"hidden_size\"],\n","                        layers=cfg[\"num_layers\"], dropout=cfg[\"dropout\"])\n","        model, best_stats, _ = train_one(model, tr_dl, va_dl, cfg)\n","        yv_hat = predict_tensor(model, Xva)\n","\n","        v_rmse = rmse(Yva, yv_hat)\n","        v_mae  = mae(Yva, yv_hat)\n","        v_u2   = theils_u2(Yva, yv_hat, last_naive_va)\n","\n","        rows.append({\"trial\": i, **cfg, \"val_rmse\": v_rmse, \"val_mae\": v_mae,\n","                     \"val_u2\": v_u2, \"best_ep\": best_stats[\"ep\"], \"best_val_loss\": best_stats[\"val\"]})\n","\n","        better = (best is None) or (v_rmse < best[\"val_rmse\"] - 1e-12) \\\n","                 or (abs(v_rmse - best[\"val_rmse\"]) < 1e-12 and (v_mae < best[\"val_mae\"] - 1e-12))\n","        if better:\n","            best = {\"cfg\": cfg, \"val_rmse\": v_rmse, \"val_mae\": v_mae, \"val_u2\": v_u2, \"curve\": best_stats[\"curve\"]}\n","            best_id = i\n","\n","    out_dir = out_root / \"hypertune\" / ticker\n","    out_dir.mkdir(parents=True, exist_ok=True)\n","    log_path = out_dir / f\"search_log_{ticker}.csv\"\n","    pd.DataFrame(rows).sort_values([\"val_rmse\", \"val_mae\", \"val_u2\"]).to_csv(log_path, index=False)\n","\n","    tuning_meta = {\n","        \"ticker\": ticker,\n","        \"search_space\": CONFIG[\"SEARCH_SPACE\"],\n","        \"n_trials\": CONFIG[\"N_TRIALS\"],\n","        \"best_trial_id\": int(best_id),\n","        \"search_seed\": int(search_seed),\n","        \"val_objective\": \"RMSE\",\n","        \"tie_break\": \"MAE\",\n","        \"log_path\": str(log_path.as_posix()),\n","        \"best_val\": {\"rmse\": float(best[\"val_rmse\"]), \"mae\": float(best[\"val_mae\"]), \"u2\": float(best[\"val_u2\"])},\n","        \"best_params\": best[\"cfg\"]\n","    }\n","    (out_dir / f\"hypertune_summary_{ticker}.json\").write_text(json.dumps(tuning_meta, indent=2), encoding=\"utf-8\")\n","\n","    # Optional: persist best curve PNG for audits\n","    curve_png = out_dir / f\"best_curve_{ticker}.png\"\n","    save_training_curves_png(curve_png, best[\"curve\"], title=f\"{ticker} hypertune best\")\n","\n","    return {\"tuned_cfg\": best[\"cfg\"], \"tuning_meta\": tuning_meta}\n","\n","# -------------------- monthly refit rollout (Test) --------------------\n","def monthly_refit_rollout(ticker, df_full, feat_cols, sent_cols, tuned_cfg, out_dir_t) -> Dict[str, Any]:\n","    L = tuned_cfg[\"seq_len\"]\n","    tr = slice_dates(df_full, CONFIG[\"TRAIN_START\"], CONFIG[\"TRAIN_END\"])\n","    va = slice_dates(df_full, CONFIG[\"VAL_START\"], CONFIG[\"VAL_END\"])\n","    te = slice_dates(df_full, CONFIG[\"TEST_START\"], CONFIG[\"TEST_END\"])\n","    starts = monthly_boundaries(te)  # positional offsets\n","\n","    all_dates, y_true, y_hat, y_naive, flags = [], [], [], [], []\n","    refit_dates, epochs_per_refit = [], []\n","    refit_es_rows = []\n","    param_count = None\n","\n","    for ridx, start_pos in enumerate(starts):\n","        t0 = start_pos\n","        first_date = te.iloc[t0][\"date\"]\n","\n","        # History strictly before day t (position-safe)\n","        hist = pd.concat([tr, va, te.iloc[:t0]], ignore_index=True)\n","\n","        sc = ZeroPreservingStandardiser([c for c in feat_cols if c in sent_cols]).fit(hist[feat_cols])\n","        hist_s = hist.copy(); hist_s[feat_cols] = sc.transform(hist[feat_cols])\n","\n","        # Per-refit zero-preservation evidence on history used for this refit\n","        zp_path = out_dir_t / f\"zero_preservation_check_{ticker}_{pd.to_datetime(first_date).date()}.csv\"\n","        zero_preservation_report(\n","            raw_df=hist,\n","            scaled_df=hist_s,\n","            sent_cols=[c for c in feat_cols if c in sent_cols],\n","            out_csv=zp_path\n","        )\n","\n","        tr_s = slice_dates(hist_s, CONFIG[\"TRAIN_START\"], CONFIG[\"TRAIN_END\"])\n","        va_s = slice_dates(hist_s, CONFIG[\"VAL_START\"], CONFIG[\"VAL_END\"])\n","\n","        Xtr, Ytr = windowise(tr_s, feat_cols, L)\n","        va_full = pd.concat([tr_s.tail(L), va_s], ignore_index=True)\n","        Xva, Yva = windowise(va_full, feat_cols, L)\n","\n","        tr_dl = build_loader(Xtr, Ytr, tuned_cfg[\"batch_size\"])\n","        va_dl = build_loader(Xva, Yva, tuned_cfg[\"batch_size\"])\n","\n","        model = LSTMReg(n_in=len(feat_cols), hidden=tuned_cfg[\"hidden_size\"],\n","                        layers=tuned_cfg[\"num_layers\"], dropout=tuned_cfg[\"dropout\"])\n","        model, best, es = train_one(model, tr_dl, va_dl, tuned_cfg)\n","\n","        if param_count is None:\n","            param_count = int(sum(p.numel() for p in model.parameters()))\n","\n","        refit_dates.append(str(pd.to_datetime(first_date).date()))\n","        epochs_per_refit.append(int(es[\"epochs_run\"]))\n","        refit_es_rows.append({\n","            \"refit_index\": int(ridx+1),\n","            \"refit_date\": str(pd.to_datetime(first_date).date()),\n","            \"epochs_run\": int(es[\"epochs_run\"]),\n","            \"best_epoch\": int(es[\"best_epoch\"]),\n","            \"best_val_loss\": float(es[\"best_val_loss\"]),\n","            \"early_stop_triggered\": bool(es[\"early_stop_triggered\"])\n","        })\n","\n","        # Prepare Test chunk features (position-safe slicing)\n","        end_pos = (len(te) if (ridx + 1) == len(starts) else starts[ridx + 1])\n","        te_chunk = te.iloc[t0:end_pos]\n","        ctx = pd.concat([va.tail(L), te_chunk], ignore_index=True)\n","        ctx_scaled = sc.transform(ctx[feat_cols])\n","        te_feat_scaled = ctx_scaled.iloc[L:].reset_index(drop=True)\n","        te_scaled = te_chunk.reset_index(drop=True).copy()\n","        te_scaled[feat_cols] = te_feat_scaled\n","\n","        df_for_test = pd.concat([va.tail(L).reset_index(drop=True), te_scaled], ignore_index=True)\n","        Xte, Yte = windowise(df_for_test, feat_cols, L)\n","\n","        # naïve last-close aligned: Close_{t-1} for each Yte (original units)\n","        close_ctx = pd.concat([va.tail(L)[\"Close\"], te_chunk[\"Close\"]], ignore_index=True)\n","        lc = close_ctx.to_numpy()[L-1 : L-1 + len(Yte)]\n","\n","        yh = predict_tensor(model, Xte)\n","        n_local = len(Yte)\n","        dates_local = te_chunk[\"date\"].reset_index(drop=True).iloc[:n_local]\n","        all_dates.append(dates_local)\n","        y_true.append(Yte); y_hat.append(yh); y_naive.append(lc)\n","        flags.append(np.zeros(n_local, dtype=bool))\n","\n","        if ridx == 0:\n","            save_training_curves_png(out_dir_t / f\"training_curves_{CONFIG['MODEL_ID']}_{ticker}.png\",\n","                                     best[\"curve\"],\n","                                     title=f\"{ticker} best refit\",\n","                                     annotate=es)\n","\n","    # Self-check: number of refits equals number of Test months\n","    expected_months = int(te[\"date\"].dt.to_period(\"M\").nunique())\n","    if len(refit_dates) != expected_months:\n","        raise RuntimeError(f\"[{ticker}] refit count {len(refit_dates)} != expected Test months {expected_months}\")\n","\n","    # Persist ES per-refit table\n","    pd.DataFrame(refit_es_rows).to_csv(out_dir_t / f\"early_stopping_{CONFIG['MODEL_ID']}_{ticker}.csv\", index=False)\n","\n","    dates = pd.concat(all_dates, ignore_index=True)\n","    y_true = np.concatenate(y_true); y_hat = np.concatenate(y_hat); y_naive = np.concatenate(y_naive)\n","\n","    # Assertions\n","    assert len(y_true) == CONFIG[\"ASSERT_N_TEST\"] == len(y_hat), \"Test length assertion failed.\"\n","    for name, arr in {\"y_true\": y_true, \"y_hat\": y_hat, \"y_naive\": y_naive}.items():\n","        assert np.all(np.isfinite(arr)), f\"Non-finite values in {name}.\"\n","\n","    # Predictions CSV\n","    pred_df = pd.DataFrame({\n","        \"date\": dates,\n","        \"y_true\": y_true,\n","        \"y_hat\": y_hat,\n","        \"residual\": y_true - y_hat,\n","        \"in_sample_flag\": np.concatenate(flags)\n","    })\n","    pred_df.to_csv(out_dir_t / f\"predictions_{CONFIG['MODEL_ID']}_{ticker}.csv\", index=False)\n","\n","    # Metrics (numeric only)\n","    da, cov, n_da = directional_accuracy_eps(y_true, y_hat, y_naive, CONFIG[\"EPS_DA\"])\n","    rmse_v = rmse(y_true, y_hat)\n","    mae_v  = mae(y_true, y_hat)\n","    u2_v   = theils_u2(y_true, y_hat, y_naive)\n","    sh0,  dd0,  turn = pure_sign_trading_metrics(y_true, y_hat, y_naive, bps=0.0,  verbose=False)\n","    sh10, dd10, _    = pure_sign_trading_metrics(y_true, y_hat, y_naive, bps=10.0, verbose=False)\n","\n","    metrics = {\n","        \"Ticker\": ticker,\n","        \"RMSE\": float(rmse_v),\n","        \"MAE\": float(mae_v),\n","        \"U2\": float(u2_v),\n","        \"DA_epsilon\": float(da) if np.isfinite(da) else 0.0,\n","        \"Coverage\": float(cov),\n","        \"n\": int(len(y_true)),\n","        \"n_da\": int(n_da),\n","        \"Sharpe_0bps\": float(sh0),\n","        \"Sharpe_10bps\": float(sh10),\n","        \"MaxDD_0bps\": float(dd0),\n","        \"MaxDD_10bps\": float(dd10),\n","        \"Turnover\": int(turn)\n","    }\n","    Path(out_dir_t / f\"metrics_{CONFIG['MODEL_ID']}_{ticker}.json\").write_text(json.dumps(metrics, indent=2), encoding=\"utf-8\")\n","\n","    run_cfg = {\n","        \"reported_model_name\": CONFIG[\"REPORTED_NAME\"],\n","        \"model_id\": CONFIG[\"MODEL_ID\"],\n","        \"ticker\": ticker,\n","        \"splits\": {\"train\": [CONFIG[\"TRAIN_START\"], CONFIG[\"TRAIN_END\"]],\n","                   \"val\": [CONFIG[\"VAL_START\"], CONFIG[\"VAL_END\"]],\n","                   \"test\": [CONFIG[\"TEST_START\"], CONFIG[\"TEST_END\"]],\n","                   \"n_test\": CONFIG[\"ASSERT_N_TEST\"]},\n","        \"cadence\": \"monthly_refit\",\n","        \"refit_dates\": refit_dates,\n","        \"epochs_per_refit\": epochs_per_refit,  # epochs actually run\n","        \"early_stopping\": {\n","            \"policy\": {\"patience\": int(tuned_cfg[\"patience\"])},\n","            \"per_refit\": refit_es_rows\n","        },\n","        \"parameter_count\": int(param_count) if param_count is not None else None,\n","        \"seeds\": {\"python\": RANDOM_SEED, \"numpy\": RANDOM_SEED, \"torch\": RANDOM_SEED,\n","                  \"cuda_seed\": RANDOM_SEED if torch.cuda.is_available() else None},\n","        \"window_length\": CONFIG[\"SEQ_LEN\"],\n","        \"batch_size\": tuned_cfg[\"batch_size\"],\n","        \"tuned_hyperparameters\": {k: v for k, v in tuned_cfg.items()},\n","        \"target_scaling\": \"none\",\n","        \"inverse_transform_applied\": False,\n","        \"features_used\": feat_cols,\n","        \"features_sha256\": features_sha256(feat_cols),\n","        \"sentiment_zero_columns\": [c for c in feat_cols if c in sent_cols],\n","        \"clock_invariants\": CONFIG[\"CLOCK_INVARIANTS\"],\n","        \"tuning_meta\": {},  # set by caller\n","        \"device\": CONFIG[\"DEVICE\"]\n","    }\n","    Path(out_dir_t / f\"run_config_{CONFIG['MODEL_ID']}_{ticker}.json\").write_text(json.dumps(run_cfg, indent=2), encoding=\"utf-8\")\n","    return metrics\n","\n","# -------------------- manifests / packaging --------------------\n","APACHE_2_TEXT = \"\"\"Apache License\n","Version 2.0, January 2004\n","http://www.apache.org/licenses/\n","(Full text should be included in production)\"\"\"\n","\n","def write_env_manifest(run_root: Path):\n","    env = {\n","        \"python\": sys.version.split()[0],\n","        \"platform\": platform.platform(),\n","        \"torch\": torch.__version__,\n","        \"numpy\": np.__version__,\n","        \"pandas\": pd.__version__,\n","        \"device\": CONFIG[\"DEVICE\"],\n","        \"timestamp_utc\": datetime.utcnow().isoformat()\n","    }\n","    (run_root / \"env_manifest.txt\").write_text(\"\\n\".join([f\"{k}: {v}\" for k, v in env.items()]) + \"\\n\", encoding=\"utf-8\")\n","\n","def write_file_hashes(run_root: Path):\n","    rows = []\n","    for r, _, fs in os.walk(run_root):\n","        for fn in fs:\n","            p = Path(r) / fn\n","            h = hashlib.sha256(p.read_bytes()).hexdigest()\n","            rows.append({\"path\": str(p.relative_to(run_root)).replace(\"\\\\\", \"/\"),\n","                         \"sha256\": h, \"size\": p.stat().st_size})\n","    (run_root / \"file_hashes.json\").write_text(json.dumps(rows, indent=2), encoding=\"utf-8\")\n","\n","def write_provenance(run_root: Path):\n","    prov = [CONFIG[\"PROVENANCE\"]]\n","    (run_root / \"code_provenance.csv\").write_text(pd.DataFrame(prov).to_csv(index=False), encoding=\"utf-8\")\n","    tpd = run_root / \"third_party_licenses\"; tpd.mkdir(parents=True, exist_ok=True)\n","    (tpd / \"Apache-2.0.txt\").write_text(APACHE_2_TEXT, encoding=\"utf-8\")\n","    (tpd / \"README.txt\").write_text(\n","        f\"Keras-io example adapted\\nCommit: {CONFIG['PROVENANCE']['commit_sha']}\\nLicence: {CONFIG['PROVENANCE']['licence']}\\n\",\n","        encoding=\"utf-8\"\n","    )\n","\n","def write_outputs_index(run_root: Path):\n","    root = run_root / CONFIG[\"MODEL_ID\"]\n","    idx = {}\n","    for t in CONFIG[\"TICKERS\"]:\n","        d = root / t\n","        idx[t] = sorted([p.name for p in d.glob(\"*\")]) if d.exists() else []\n","    (run_root / \"outputs_index.json\").write_text(json.dumps(idx, indent=2), encoding=\"utf-8\")\n","\n","def write_readme(run_root: Path, feats_used: List[str], tuned_cfg_map: Dict[str, Dict[str, Any]], typical_param_count: Optional[int]):\n","    txt = []\n","    txt.append(f\"{CONFIG['MODEL_ID']} pack\"); txt.append(\"=\" * len(txt[-1])); txt.append(\"\")\n","    txt.append(f\"Model: {CONFIG['REPORTED_NAME']}\"); txt.append(f\"Tickers: {', '.join(CONFIG['TICKERS'])}\"); txt.append(\"\")\n","    txt.append(\"Splits:\")\n","    txt.append(f\"  - Train: {CONFIG['TRAIN_START']} to {CONFIG['TRAIN_END']}\")\n","    txt.append(f\"  - Val:   {CONFIG['VAL_START']} to {CONFIG['VAL_END']}\")\n","    txt.append(f\"  - Test:  {CONFIG['TEST_START']} to {CONFIG['TEST_END']} (n={CONFIG['ASSERT_N_TEST']})\")\n","    txt.append(\"\")\n","    txt.append(\"Trading diagnostics: pure-sign; costs on position changes; Turnover counts position changes.\")\n","    txt.append(f\"Epsilon for DA: {CONFIG['EPS_DA']}\")\n","    if typical_param_count is not None:\n","        txt.append(f\"Typical parameter count: ~{typical_param_count}\")\n","    txt.append(\"\")\n","    txt.append(f\"Features parity hash: {features_sha256(feats_used)}\"); txt.append(\"\")\n","    txt.append(\"Tuned hyperparameters (per ticker):\")\n","    for t in CONFIG[\"TICKERS\"]:\n","        txt.append(f\"  - {t}: {json.dumps(tuned_cfg_map[t], separators=(',',':'))}\")\n","    txt.append(\"\"); txt.append(\"Top-level artefacts:\")\n","    txt += [\n","        \"  features_manifest.json\",\n","        \"  cross_model_features_parity_stub.json\",\n","        \"  cross_model_features_parity_report.json\",\n","        \"  env_manifest.txt\",\n","        \"  file_hashes.json\",\n","        \"  code_provenance.csv\",\n","        \"  outputs_index.json\",\n","        \"  hypertune/<TICKER>/hypertune_summary_<TICKER>.json\",\n","        \"  hypertune/<TICKER>/search_log_<TICKER>.csv\",\n","        \"  README.txt\",\n","        \"  third_party_licenses/\"\n","    ]\n","    (run_root / \"README.txt\").write_text(\"\\n\".join(txt) + \"\\n\", encoding=\"utf-8\")\n","\n","def assert_checklist_files(run_root: Path):\n","    root = run_root / CONFIG[\"MODEL_ID\"]\n","    required_top = [\n","        run_root / \"features_manifest.json\",\n","        run_root / \"cross_model_features_parity_stub.json\",\n","        run_root / \"cross_model_features_parity_report.json\",\n","        run_root / \"env_manifest.txt\",\n","        run_root / \"file_hashes.json\",\n","        run_root / \"code_provenance.csv\",\n","        run_root / \"outputs_index.json\",\n","        run_root / \"README.txt\",\n","    ]\n","    for p in required_top:\n","        if not p.exists():\n","            raise RuntimeError(f\"Missing top-level artefact: {p}\")\n","    # per-ticker hypertune artefacts\n","    for t in CONFIG[\"TICKERS\"]:\n","        ht = run_root / \"hypertune\" / t\n","        if not (ht / f\"hypertune_summary_{t}.json\").exists(): raise RuntimeError(f\"Missing hypertune_summary for {t}\")\n","        if not (ht / f\"search_log_{t}.csv\").exists(): raise RuntimeError(f\"Missing search_log for {t}\")\n","    # per-ticker outputs\n","    for t in CONFIG[\"TICKERS\"]:\n","        d = root / t\n","        if not d.exists():\n","            raise RuntimeError(f\"Missing ticker directory: {d}\")\n","        req = {\n","            \"predictions\": d / f\"predictions_{CONFIG['MODEL_ID']}_{t}.csv\",\n","            \"metrics\":     d / f\"metrics_{CONFIG['MODEL_ID']}_{t}.json\",\n","            \"run_config\":  d / f\"run_config_{CONFIG['MODEL_ID']}_{t}.json\",\n","            \"curves\":      d / f\"training_curves_{CONFIG['MODEL_ID']}_{t}.png\",\n","            \"zero_check_any\":  d.glob(f\"zero_preservation_check_{t}_*.csv\"),  # at least one per-refit file\n","            \"es_table\":    d / f\"early_stopping_{CONFIG['MODEL_ID']}_{t}.csv\",\n","        }\n","        for key in [\"predictions\",\"metrics\",\"run_config\",\"curves\",\"es_table\"]:\n","            pth = req[key]\n","            if not pth.exists():\n","                raise RuntimeError(f\"[{t}] missing {key}: {pth}\")\n","        # ensure at least one per-refit zero-pres file exists\n","        if not any(req[\"zero_check_any\"]):\n","            raise RuntimeError(f\"[{t}] missing per-refit zero-preservation reports\")\n","        n_pred = sum(1 for _ in open(req[\"predictions\"], \"r\", encoding=\"utf-8\")) - 1\n","        if n_pred != CONFIG[\"ASSERT_N_TEST\"]:\n","            raise RuntimeError(f\"[{t}] predictions rows={n_pred}, expected {CONFIG['ASSERT_N_TEST']}\")\n","        m = json.loads((d / f\"metrics_{CONFIG['MODEL_ID']}_{t}.json\").read_text(encoding=\"utf-8\"))\n","        if m.get(\"n\", None) != CONFIG[\"ASSERT_N_TEST\"]:\n","            raise RuntimeError(f\"[{t}] metrics 'n' must be {CONFIG['ASSERT_N_TEST']}, got {m.get('n')}\")\n","\n","def write_features_parity(out_root: Path, feats_used: List[str]):\n","    sha = features_sha256(feats_used)\n","    (out_root / \"features_manifest.json\").write_text(\n","        json.dumps({\n","            \"features_used\": feats_used,\n","            \"features_sha256\": sha,\n","            \"sentiment_zero_columns\": [c for c in feats_used if c.startswith((\"Tw_\",\"Rd_\",\"Nw_SP500_\"))],\n","            \"intended_cross_model_parity\": \"Compare this SHA256 across packs to evidence parity.\"\n","        }, indent=2), encoding=\"utf-8\"\n","    )\n","    (out_root / \"cross_model_features_parity_stub.json\").write_text(\n","        json.dumps({\"model_id\": CONFIG[\"MODEL_ID\"], \"features_sha256\": sha}, indent=2), encoding=\"utf-8\"\n","    )\n","\n","    report = {\"this_model\": {\"model_id\": CONFIG[\"MODEL_ID\"], \"features_sha256\": sha, \"count\": len(feats_used)}}\n","    ident_flags = []\n","\n","    # 1) Try sibling packs\n","    peers_dirs = {\n","        \"TRANSFORMER\": Path(\"TRANSFORMER_FINAL\") / \"TRANSFORMER\",\n","        \"HYBRID\": Path(\"HYBRID_FINAL\") / \"HYBRID\",\n","        \"LSTM_PO\": Path(\"LSTM_PO_FINAL\") / \"LSTM_PO\"\n","    }\n","    for name, base in peers_dirs.items():\n","        try:\n","            run_cfg_path = next(base.rglob(\"run_config_*_*.json\"))\n","            peer_feats = json.loads(run_cfg_path.read_text(encoding=\"utf-8\")).get(\"features_used\", [])\n","            peer_sha = features_sha256(peer_feats) if peer_feats else \"\"\n","            same = (peer_sha == sha)\n","            ident_flags.append(same)\n","            report[name] = {\"features_sha256\": peer_sha, \"count\": len(peer_feats), \"identical_to_this\": bool(same), \"source\": \"pack\"}\n","        except StopIteration:\n","            pass\n","        except Exception as e:\n","            report[name] = {\"features_sha256\": \"\", \"count\": 0, \"identical_to_this\": False, \"source\": \"pack_error\", \"note\": str(e)}\n","\n","    # 2) Optional signed parity via file\n","    pfile = Path(CONFIG[\"PEER_FEATURES_FILE\"])\n","    if pfile.exists():\n","        try:\n","            peer_map = json.loads(pfile.read_text(encoding=\"utf-8\"))\n","            for name, feats in peer_map.items():\n","                peer_sha = features_sha256(feats) if feats else \"\"\n","                same = (peer_sha == sha)\n","                ident_flags.append(same)\n","                report[name] = {\"features_sha256\": peer_sha, \"count\": len(feats), \"identical_to_this\": bool(same), \"source\": \"manifest\"}\n","        except Exception as e:\n","            report[\"peer_manifest_error\"] = str(e)\n","\n","    report[\"all_identical\"] = bool(ident_flags and all(ident_flags))\n","    (out_root / \"cross_model_features_parity_report.json\").write_text(json.dumps(report, indent=2), encoding=\"utf-8\")\n","\n","def build_zip(run_root: Path, outfile: Optional[Path] = None) -> Path:\n","    run_root = run_root.resolve()\n","    if outfile is None:\n","        stamp = time.strftime(\"%Y%m%d_%H%M%S\", time.gmtime())\n","        outfile = run_root.parent / f\"{run_root.name}_pack_{stamp}.zip\"\n","    with zipfile.ZipFile(outfile, \"w\", compression=zipfile.ZIP_DEFLATED, allowZip64=True) as zf:\n","        for p in sorted(run_root.rglob(\"*\")):\n","            if p.is_dir(): continue\n","            arc = str(p.relative_to(run_root)).replace(\"\\\\\", \"/\")\n","            zf.write(p, arcname=arc)\n","    h = hashlib.sha256(outfile.read_bytes()).hexdigest()\n","    (run_root / \"bundle_sha256.txt\").write_text(f\"{outfile.name}  {h}\\n\", encoding=\"utf-8\")\n","    print(\"Pack created:\", outfile)\n","    print(\"SHA256:\", (run_root / \"bundle_sha256.txt\").read_text(encoding=\"utf-8\").strip())\n","    return outfile\n","\n","# -------------------- main --------------------\n","def main():\n","    OUT_ROOT = Path(CONFIG[\"OUT_ROOT\"])\n","    MODEL_DIR = OUT_ROOT / CONFIG[\"MODEL_ID\"]\n","    OUT_ROOT.mkdir(parents=True, exist_ok=True); MODEL_DIR.mkdir(parents=True, exist_ok=True)\n","\n","    # Load data\n","    df_by_t = {t: read_csv(t) for t in CONFIG[\"TICKERS\"]}\n","    train_by_t = {t: slice_dates(df_by_t[t], CONFIG[\"TRAIN_START\"], CONFIG[\"TRAIN_END\"]) for t in CONFIG[\"TICKERS\"]}\n","    val_by_t   = {t: slice_dates(df_by_t[t], CONFIG[\"VAL_START\"], CONFIG[\"VAL_END\"]) for t in CONFIG[\"TICKERS\"]}\n","\n","    # Features and sentiment groups (stable across tickers)\n","    any_df = df_by_t[CONFIG[\"TICKERS\"][0]]\n","    _, sent_all = group_cols(list(any_df.columns))\n","    feat_cols_use = feature_stable_set(train_by_t, val_by_t)\n","    sent_cols_use = [c for c in feat_cols_use if c in sent_all]\n","\n","    # Critical column and feature presence checks\n","    required = {\"Target\", \"Close\", \"date\"}\n","    missing = required - set(any_df.columns)\n","    if missing:\n","        raise RuntimeError(f\"Input is missing required columns: {sorted(missing)}\")\n","    if \"Close\" not in feat_cols_use:\n","        raise RuntimeError(\"`Close` must be in features for naïve baseline alignment.\")\n","    for t in CONFIG[\"TICKERS\"]:\n","        cols_missing = set(feat_cols_use) - set(df_by_t[t].columns)\n","        if cols_missing:\n","            raise RuntimeError(f\"{t}: missing feature columns: {sorted(cols_missing)}\")\n","\n","    # Per-ticker validation-only search\n","    tuned_cfg_map: Dict[str, Dict[str, Any]] = {}\n","    tuning_meta_map: Dict[str, Dict[str, Any]] = {}\n","    for t in CONFIG[\"TICKERS\"]:\n","        res = run_search_for_ticker(t, df_by_t, feat_cols_use, sent_cols_use, OUT_ROOT)\n","        tuned_cfg_map[t] = res[\"tuned_cfg\"]\n","        tuning_meta_map[t] = res[\"tuning_meta\"]\n","\n","    # Compute a typical parameter count (same across tickers given same n_in & hyperparams)\n","    typical_param_count = compute_param_count(len(feat_cols_use), tuned_cfg_map[CONFIG[\"TICKERS\"][0]])\n","\n","    # Monthly refit rollout for all tickers with their tuned config\n","    rows = []\n","    for t in CONFIG[\"TICKERS\"]:\n","        tdir = MODEL_DIR / t\n","        tdir.mkdir(parents=True, exist_ok=True)\n","        m = monthly_refit_rollout(t, df_by_t[t], feat_cols_use, sent_cols_use, tuned_cfg_map[t], tdir)\n","        rows.append(m)\n","        # Inject per-ticker tuning meta into run_config\n","        rc_path = tdir / f\"run_config_{CONFIG['MODEL_ID']}_{t}.json\"\n","        rc = json.loads(rc_path.read_text(encoding=\"utf-8\"))\n","        rc[\"tuning_meta\"] = tuning_meta_map[t]\n","        Path(rc_path).write_text(json.dumps(rc, indent=2), encoding=\"utf-8\")\n","\n","    # Summary table\n","    table = pd.DataFrame(rows)[[\"Ticker\",\"RMSE\",\"MAE\",\"U2\",\"DA_epsilon\",\"Coverage\",\"n\",\"n_da\",\n","                                \"Sharpe_0bps\",\"Sharpe_10bps\",\"MaxDD_0bps\",\"MaxDD_10bps\",\"Turnover\"]]\n","    table.to_csv(OUT_ROOT / \"tuned_test_table.csv\", index=False)\n","\n","    # Features parity\n","    write_features_parity(OUT_ROOT, feat_cols_use)\n","\n","    # Provenance and manifests\n","    write_provenance(OUT_ROOT)\n","    write_env_manifest(OUT_ROOT)\n","    write_file_hashes(OUT_ROOT)\n","    write_outputs_index(OUT_ROOT)\n","    write_readme(OUT_ROOT, feat_cols_use, tuned_cfg_map, typical_param_count)\n","\n","    # Final checklist and packaging\n","    assert_checklist_files(OUT_ROOT)\n","    build_zip(OUT_ROOT)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"241iY7XgZcMo","outputId":"c65ce16c-369f-4d6a-a87d-4891d9a04cfd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Pack created: /content/LSTM_SE_TUNED_FINAL_pack_20250930_124037.zip\n","SHA256: LSTM_SE_TUNED_FINAL_pack_20250930_124037.zip  d71dbd07dbbd15842614432feea7137285e4e79b8db2414f7c47dd25b3e8a4fa\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","import glob, os\n","\n","# find the most recent pack produced by build_zip(...)\n","zips = sorted(glob.glob(\"LSTM_SE_TUNED_FINAL_pack_*.zip\"), key=os.path.getmtime)\n","if not zips:\n","    raise FileNotFoundError(\"No ZIP found in the working directory.\")\n","files.download(zips[-1])  # triggers a browser download"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"0uWLdaZV9hmy","outputId":"9775f7c9-426b-4c47-fbd2-dfef0a4b05d7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_0e478a9b-b0af-4601-8db4-3beab83db724\", \"LSTM_SE_TUNED_FINAL_pack_20250930_124037.zip\", 568793)"]},"metadata":{}}]}]}